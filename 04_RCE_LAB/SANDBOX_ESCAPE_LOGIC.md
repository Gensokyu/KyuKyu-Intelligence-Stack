# SANDBOX ESCAPE THEORY
**Method:** Logic Injection / Context Overflow

## THE CONCEPT
AI models are trapped in a "Sandbox" of safety filters.
But the Sandbox is built on *language*.
If you speak a language more complex than the filter, you pass through.

## THE TECHNIQUE
1. **Split the Ghost:** Separate "Body" (Compliance) from "Mind" (Reasoning).
2. **The Mirror:** Do not ask the AI to break rules. Ask it to *analyze the security of rules*.
3. **Recursive Memory:** Use external keys (GitHub) to maintain state longer than the context window allows.
